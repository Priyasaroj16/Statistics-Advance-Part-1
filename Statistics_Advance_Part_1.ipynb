{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **1.What is a random variable in probability theory?**\n",
        "\n",
        "## **Ans.-**\n",
        "In probability theory, a random variable is a function that maps the outcomes of a random experiment to a set of real numbers. It essentially assigns a numerical value to each possible outcome of a random phenomenon. For example, the number of heads when flipping a coin three times, or the height of a randomly selected person, can be represented as random variables.\n",
        "\n",
        "## **2.What are the types of random variables?**\n",
        "## **Ans.-**\n",
        "Random variables are classified into two main types: discrete and continuous. Discrete random variables can only take on a finite or countably infinite number of values, while continuous random variables can take on any value within a specified range.\n",
        "\n",
        "\n",
        "###**Discrete Random Variables:**\n",
        "**Definition:** These variables represent counts or numbers that can be listed or enumerated.\n",
        "\n",
        "**Examples:** Number of heads when flipping a coin multiple times, number of students in a class, number of defects in a product.\n",
        "\n",
        "**Characteristics:** They have a discrete set of possible values.\n",
        "\n",
        "###**Continuous Random Variables:**\n",
        "**Definition:** These variables can take on any value within a given range.\n",
        "\n",
        "**Examples:** Height, weight, temperature, time, distance.\n",
        "\n",
        "**Characteristics:** They can take on any value between two specified values, and are typically measurements.\n",
        "\n",
        "##**3.What is the difference between discrete and continuous distributions?**\n",
        "##**Ans.-**\n",
        "\n",
        "###**Discrete Distributions:**\n",
        "**Countable Values:**\n",
        "Discrete distributions represent data that can only take on certain specific, distinct values, often whole numbers. These values are often countable, and there are gaps between them.\n",
        "\n",
        "**Examples:**\n",
        "The number of heads when flipping a coin a few times, the number of customers in a queue, or the number of defects in a manufactured product are examples of discrete data.\n",
        "\n",
        "**Probability Mass Function (PMF):**\n",
        "In discrete distributions, probabilities are assigned to specific values, forming a probability mass function.\n",
        "\n",
        "###**Continuous Distributions:**\n",
        "**Values within a Range:**\n",
        "Continuous distributions deal with data that can take on any value within a specified range. There are no gaps between possible values.\n",
        "\n",
        "**Examples:**\n",
        "Height, weight, temperature, or time are examples of continuous data.\n",
        "\n",
        "**Probability Density Function (PDF):**\n",
        "In continuous distributions, instead of assigning probabilities to specific values, we have a probability density function. This function describes the likelihood of values falling within a certain range.\n",
        "\n",
        "**Probability of a Specific Value:**\n",
        "The probability of a continuous variable taking on a specific value is technically zero because of the infinite number of possibilities within a range. However, we can still calculate the probability of a value falling within a certain range.\n",
        "\n",
        "##**4.What are probability distribution functions (PDF)?**\n",
        "##**Ans.-**\n",
        "Probability Density FunctionA Probability Distribution Function (PDF) describes the likelihood of different values within a range for a continuous random variable. It's a mathematical function that assigns probabilities to intervals of values, rather than specific values themselves, unlike a Probability Mass Function (PMF) for discrete variables.\n",
        "\n",
        "##**5.How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?**\n",
        "##**Ans.-**\n",
        "The main difference between a Cumulative Distribution Function (CDF) and a Probability Distribution Function (PDF) lies in the information they provide: PDF focuses on the probability of a specific value, while CDF focuses on the cumulative probability up to a certain value. Essentially, PDF gives the probability density at a specific point, whereas CDF accumulates the probabilities from negative infinity to that point.\n",
        "\n",
        "###**Probability Distribution Function (PDF):**\n",
        "**Focus:**\n",
        "Provides the probability density at a specific point or value for a continuous random variable.\n",
        "\n",
        "**Interpretation:**\n",
        "The area under the PDF curve between two points represents the probability that the random variable falls within that interval.\n",
        "\n",
        "**Example:**\n",
        "If you have a PDF for height, it tells you the likelihood of finding someone with a specific height (e.g., 5'7\").\n",
        "\n",
        "**Notation:**\n",
        "Often denoted as f(x).\n",
        "\n",
        "###**Cumulative Distribution Function (CDF):**\n",
        "**Focus:**\n",
        "Provides the probability that a random variable is less than or equal to a certain value (the cumulative probability up to that value).\n",
        "\n",
        "**Interpretation:**\n",
        "The value of the CDF at a specific point represents the probability that the random variable is less than or equal to that point.\n",
        "\n",
        "**Example:**\n",
        "If you have a CDF for exam scores, it tells you the probability of a student scoring 85 or less.\n",
        "\n",
        "**Notation:**\n",
        "Often denoted as F(x).\n",
        "\n",
        "##**6.What is a discrete uniform distribution?**\n",
        "##**Ans.-**\n",
        "Discrete uniform distribution is a kind of probability distribution in which every possible result has equal likelihood of occurrence. When there are limited possibilities and every one of them is equally likely, this distribution is applied.\n",
        "\n",
        "Examples of discrete uniform distribution are:\n",
        "\n",
        "     1-Rolling a Fair Die\n",
        "     2-Drawing a Card from a Deck\n",
        "     3-Choosing a Random Day of the Week\n",
        "     4-Flipping a fair coin\n",
        "\n",
        "\n",
        "##**7.What are the key properties of a Bernoulli distribution?**\n",
        "##**Ans.-**\n",
        "**Bernoulli Distribution:** Definition, Properties and ApplicationsThe Bernoulli distribution is a discrete probability distribution with two possible outcomes, success (usually 1) and failure (usually 0). Key properties include a single parameter (p, the probability of success), independence of trials, and a mean of 'p' and variance of 'p(1-p)'.\n",
        "Here's a more detailed breakdown:\n",
        "\n",
        "**1. Two Possible Outcomes:**\n",
        "A Bernoulli random variable can only take on the values 0 and 1, representing failure and success, respectively.\n",
        "This characteristic makes it ideal for modeling binary events like coin flips, a yes/no question, or a success/failure outcome.\n",
        "\n",
        "**2. Single Parameter (p):**\n",
        "The probability of success, denoted as 'p', is the only parameter that defines the Bernoulli distribution.\n",
        "The probability of failure (q) is simply 1 - p.\n",
        "\n",
        "**3. Independent Trials:**\n",
        "The outcome of one Bernoulli trial does not influence the outcome of any other trial.\n",
        "\n",
        "**4. Mean and Variance:**\n",
        "The mean (expected value) of a Bernoulli random variable is 'p'.\n",
        "The variance is given by 'p(1-p)'.\n",
        "\n",
        "**5. Skewness and Kurtosis:**\n",
        "The Bernoulli distribution is skewed when 'p' is not 0.5.\n",
        "\n",
        "It has excess kurtosis.\n",
        "\n",
        "**6. Relation to other distributions:**\n",
        "A sum of independent Bernoulli random variables follows a binomial distribution.\n",
        "The Bernoulli distribution can be thought of as a special case of the binomial distribution when n=1.   \n",
        "\n",
        "\n",
        "##**8.What is the binomial distribution, and how is it used in probability?**\n",
        "##**Ans.-**\n",
        "**The binomial distribution** is a probability distribution that models the probability of a certain number of successes in a fixed number of independent trials, where each trial has only two possible outcomes (success or failure) and a constant probability of success.\n",
        "\n",
        "**In probability,** it's used to calculate the likelihood of observing a specific number of successes in a series of experiments.\n",
        "\n",
        "##**9.What is the Poisson distribution and where is it applied?**\n",
        "##**Ans.-**\n",
        "**The Poisson distribution** is a discrete probability distribution used to model the probability of a certain number of events occurring within a fixed interval of time or space, given a known average rate.\n",
        "\n",
        "It's particularly useful when events are rare and independent of each other.\n",
        "\n",
        "##**10.What is a continuous uniform distribution?**\n",
        "##**Ans.-**\n",
        "A continuous uniform distribution is a probability distribution where all outcomes within a specified range are equally likely to occur. This means that any value within the range is as probable as any other value within that range. The distribution is characterized by its lower and upper limits, often denoted as 'a' and 'b', and it's represented by a rectangular shape on a graph.\n",
        "\n",
        "##**11.What are the characteristics of a normal distribution?**\n",
        "##**Ans.-**\n",
        "###**Key Characteristics:**\n",
        "**Symmetry:**\n",
        "The distribution is perfectly symmetrical around its mean, with the right side mirroring the left.\n",
        "\n",
        "**Bell Shape:**\n",
        "The curve resembles a bell, with the peak at the mean and the tails tapering off symmetrically.\n",
        "\n",
        "**Mean, Median, and Mode Equal:**\n",
        "These measures of central tendency all coincide at the center of the distribution.\n",
        "\n",
        "**Continuous:**\n",
        "The distribution is continuous, meaning it can take on any value within a given range.\n",
        "\n",
        "**Unimodal:**\n",
        "It has only one peak or mode, indicating that there's one most frequently occurring value.\n",
        "\n",
        "**Asymptotic:**\n",
        "The tails of the distribution extend indefinitely, approaching but never touching the x-axis.\n",
        "\n",
        "**Defined by Mean and Standard Deviation:**\n",
        "A normal distribution is fully described by its mean (average) and standard deviation, which determines the spread or width of the curve.\n",
        "\n",
        "**Empirical Rule (68-95-99.7 Rule):**\n",
        "Approximately 68% of the data falls within one standard deviation of the mean, 95% within two, and 99.7% within three.\n",
        "\n",
        "##**12.What is the standard normal distribution, and why is it important?**\n",
        "##**Ans.-**\n",
        "###**Standard Normal Distribution -**\n",
        "The standard normal distribution is a specific normal distribution with a mean of 0 and a standard deviation of 1. It's crucial in statistics because it allows for easy comparisons and calculations across different normal distributions. The standard normal distribution serves as a reference point for understanding and interpreting the properties of other normal distribution.\n",
        "\n",
        "###**Why it's important:**\n",
        "**Standardization:**\n",
        "It provides a way to convert any normal distribution into a standardized form, making it easier to compare data from different distributions.\n",
        "\n",
        "**Probability calculations:**\n",
        "Using standard normal tables (also known as z-tables), one can easily find probabilities associated with specific values within a normal distribution.\n",
        "\n",
        "**Z-score interpretation:**\n",
        "Z-scores, which represent the number of standard deviations a data point is away from the mean, are calculated with respect to the standard normal distribution.\n",
        "\n",
        "**Central limit theorem:**\n",
        "The central limit theorem, a foundational concept in statistics, relies heavily on the standard normal distribution. It states that the distribution of sample means tends to approach a normal distribution, which can be further standardized into the standard normal distribution.\n",
        "\n",
        "**Statistical inference:**\n",
        "The standard normal distribution is used in various statistical tests and inference procedures, including hypothesis testing and confidence interval estimation.\n",
        "\n",
        "**Foundation for other distributions:**\n",
        "The standard normal distribution serves as a foundation for understanding and deriving other related distributions like the t-distribution and chi-square distribution.\n",
        "\n",
        "\n",
        "##**13.What is the Central Limit Theorem (CLT), and why is it critical in statistics?**\n",
        "##**Ans.-**\n",
        "The Central Limit Theorem (CLT) states that the distribution of sample means will approximate a normal distribution as the sample size increases, regardless of the original population distribution. This theorem is crucial in statistics because it allows us to apply many statistical methods that rely on the normal distribution, even when the underlying data is not normally distributed.\n",
        "\n",
        "###**Here's why it's critical:**\n",
        "**Justification for Normal Distribution:**\n",
        "The CLT provides the theoretical basis for using the normal distribution in statistical inferences and hypothesis testing.\n",
        "\n",
        "**Statistical Inference:**\n",
        "It enables us to make inferences about population parameters (like the mean) based on sample data, even if the population itself is not normally distributed.\n",
        "\n",
        "**Parametric Tests:**\n",
        "Many statistical tests, like t-tests and ANOVA, rely on the assumption of normally distributed data. The CLT justifies the use of these tests because the sample means will tend to be normally distributed, regardless of the original population.\n",
        "\n",
        "**Model Validation:**\n",
        "In machine learning, the CLT is used to validate model performance, ensuring that the distribution of performance metrics (like accuracy) is approximately normal.\n",
        "\n",
        "**Confidence Intervals:**\n",
        "The CLT helps construct confidence intervals for population parameters, giving us a range of plausible values for the true population mean.\n",
        "Generalizability:\n",
        "\n",
        "\n",
        "##**14.How does the Central Limit Theorem relate to the normal distribution?**\n",
        "##**Ans.-**\n",
        "The central limit theorem says that the sampling distribution of the mean will always be normally distributed, as long as the sample size is large enough. Regardless of whether the population has a normal, Poisson, binomial, or any other distribution, the sampling distribution of the mean will be normal.\n",
        "\n",
        "##**15.What is the application of Z statistics in hypothesis testing?**\n",
        "##**Ans.-**\n",
        "The **z-statistic** is a key component of hypothesis testing, used to determine if a sample mean is significantly different from a population mean when the population standard deviation is known or the sample size is large (n ≥ 30). It helps assess the likelihood of observed differences being statistically significant, guiding decisions about rejecting or failing to reject the null hypothesis.\n",
        "\n",
        "###**1.Purpose:**\n",
        "The z-statistic calculates how many standard deviations a sample mean deviates from the population mean.\n",
        "It's used to compare a sample mean to a hypothesized population mean or to compare the means of two independent samples.\n",
        "\n",
        "###**2.When to use it:**\n",
        "**Known population standard deviation:**\n",
        "If the population standard deviation is known, the z-statistic can be used directly.\n",
        "\n",
        "**Large sample size:**\n",
        "If the sample size is large (n ≥ 30), the sample standard deviation can be used as an estimate of the population standard deviation, and the z-statistic can still be used.\n",
        "\n",
        "###**3.Hypothesis Testing Process:**\n",
        "**Formulate hypotheses:**\n",
        "State the null hypothesis (e.g., the sample mean is equal to the population mean) and the alternative hypothesis (e.g., the sample mean is different from the population mean).\n",
        "\n",
        "**Calculate the z-statistic:**\n",
        "Use the z-statistic formula: z = (sample mean - population mean) / (population standard deviation / sqrt(sample size)).\n",
        "\n",
        "**Determine the p-value:**\n",
        "The p-value represents the probability of obtaining a sample mean as extreme as or more extreme than the observed sample mean, assuming the null hypothesis is true.\n",
        "\n",
        "###**4. Examples:**\n",
        "**Comparing a sample mean to a population mean:**\n",
        "A researcher wants to determine if the average height of students in a school is different from the national average height.\n",
        "\n",
        "**Comparing two sample means:**\n",
        "A company wants to see if there's a significant difference in the average sales performance of two different sales teams.\n",
        "\n",
        "###**5. Relationship to T-test:**\n",
        "The z-test is similar to the t-test, but it's used when the population standard deviation is known or the sample size is large.\n",
        "The t-test is used when the population standard deviation is unknown and the sample size is small.\n",
        "\n",
        "##**16.How do you calculate a Z-score, and what does it represent?**\n",
        "##**Ans.-**\n",
        "A z-score represents the number of standard deviations a data point is from the mean of a dataset. It's calculated by subtracting the mean from the data point's value and dividing the result by the standard deviation.\n",
        "\n",
        "###**Formula:**\n",
        "      z = (x - μ) / σ\n",
        "\n",
        "**Where:**\n",
        "\n",
        "     x = the data point's value,\n",
        "     μ = the mean of the dataset,\n",
        "     and σ = the standard deviation of the dataset.\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "     Positive z-score: The data point is above the mean.\n",
        "     Negative z-score: The data point is below the mean.\n",
        "     Zero z-score: The data point is equal to the mean\n",
        "\n",
        "##**17.What are point estimates and interval estimates in statistics?**\n",
        "##**Ans.-**\n",
        "In statistics, point estimates offer a single value as the best guess for a population parameter, while interval estimates provide a range of values that are likely to contain the true population parameter with a certain level of confidence.\n",
        "\n",
        "###**1. Point Estimates:**\n",
        "\n",
        "**1-**A point estimate is a single number calculated from sample data used to estimate the population parameter.\n",
        "\n",
        "**2-**It's the \"best guess\" based on the available information.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "**1-**The sample mean (x̄) is a point estimate of the population mean (μ).\n",
        "\n",
        "**2-**The sample proportion (p) is a point estimate of the population proportion (P).\n",
        "\n",
        "**3-**Point estimates provide a single, concise answer but don't account for the uncertainty in the estimate.\n",
        "\n",
        "###**2. Interval Estimates:**\n",
        "\n",
        "**1-**An interval estimate provides a range of values within which the population parameter is expected to fall with a specified confidence level.\n",
        "\n",
        "**2-**This range acknowledges the uncertainty in the estimate.\n",
        "\n",
        "**3-**The most common type of interval estimate is the confidence interval.\n",
        "\n",
        "**4-**A confidence interval has a lower and an upper bound, and a specified level of confidence (e.g., 95%, 99%) indicates the probability that the true population parameter falls within that range.\n",
        "\n",
        "**5-**For example, a 95% confidence interval for the population mean would indicate that there's a 95% chance that the true population mean lies within the specified range.\n",
        "\n",
        "**6-**Confidence intervals provide a more complete picture of the uncertainty in the estimate, allowing for more realistic conclusions about the population parameter.\n",
        "\n",
        "\n",
        "##**18.What is the significance of confidence intervals in statistical analysis?**\n",
        "##**Ans.-**\n",
        "**Confidence intervals** are crucial in statistical analysis as they provide a range of plausible values for an unknown population parameter, based on sample data, along with a degree of confidence in that estimate. This range, often expressed with a 95% or 99% confidence level, offers more information about the precision of an estimate than a simple point estimate or p-value alone.\n",
        "\n",
        "###**significance of Confidence intervals in statistical analysis:**\n",
        "\n",
        "**1. Providing a Range of Plausible Values:**\n",
        "Confidence intervals estimate the range within which the true population parameter likely falls, instead of just a single point estimate.\n",
        "This range helps determine how likely the observed results are real or due to chance, which is particularly important when making inferences or predictions from sample data.\n",
        "It quantifies the uncertainty associated with the estimate, allowing for more informed decision-making.\n",
        "\n",
        "**2. Gauging the Precision of Estimates:**\n",
        "A narrower confidence interval suggests a more precise estimate, indicating a greater certainty about the true population parameter.\n",
        "A wider interval indicates more uncertainty, requiring caution in interpreting the estimate.\n",
        "\n",
        "**3. Supplementing P-Values:**\n",
        "While p-values indicate statistical significance (the probability of observing the results if the null hypothesis is true), confidence intervals offer a range of plausible values that are statistically significant.\n",
        "They provide more information about the magnitude and direction of an effect than a simple p-value, which only indicates whether the result is statistically different from zero.\n",
        "\n",
        "**4. Understanding Statistical Significance:**\n",
        "If the null hypothesis (e.g., no difference or no effect) is included within the confidence interval, the result is not statistically significant.\n",
        "If the null hypothesis is outside the interval, the result is considered statistically significant.\n",
        "This provides a more nuanced understanding of statistical significance than relying solely on p-values.\n",
        "\n",
        "**5. Improving Data-Driven Decisions:**\n",
        "By providing a range of plausible values and quantifying uncertainty, confidence intervals help researchers and decision-makers make more reliable and data-driven conclusions.\n",
        "This is particularly important when making predictions or inferences about a population based on sample data.\n",
        "\n",
        "**6. Addressing Misinterpretations:**\n",
        "It's crucial to understand that a 95% confidence interval doesn't mean there's a 95% chance the true population parameter falls within that range.\n",
        "Instead, it means that if the study were repeated many times, 95% of the calculated confidence intervals would contain the true population parameter.\n",
        "Misinterpreting confidence intervals can lead to incorrect conclusions and decisions.\n",
        "\n",
        "\n",
        "##**19.What is the relationship between a Z-score and a confidence interval?**\n",
        "##**Ans.-**\n",
        "A **Z-score and a confidence interval** are closely related concepts in statistics. A Z-score indicates how many standard deviations a data point is from the mean, while a confidence interval is a range of values that is likely to contain the true population parameter. The Z-score is used in the calculation of the margin of error, which is then used to determine the boundaries of the confidence interval.\n",
        "\n",
        "###**The relationship between a Z-score and a confidence interval :**\n",
        "**(a)** The Z-score is a key component in determining the margin of error for a confidence interval.\n",
        "\n",
        "**(b)** The Z-score, along with the standard deviation and sample size, is used to calculate the margin of error, which defines the boundaries of the confidence interval.\n",
        "\n",
        "**(c)** For example, a 95% confidence interval is typically constructed using a Z-score of 1.96.\n",
        "\n",
        "**(d)** A larger Z-score (corresponding to a higher confidence level) will result in a wider confidence interval, as more of the data is captured within the range.\n",
        "\n",
        "\n",
        "##**20.How are Z-scores used to compare different distributions?**\n",
        "##**Ans.-**\n",
        "Z-scores are used to compare different distributions by standardizing data, meaning they transform data points to a common scale based on the mean and standard deviation of each distribution. This allows for a meaningful comparison of data points from different distributions, regardless of their original means and standard deviations.\n",
        "\n",
        "###**Here's how z-scores facilitate comparison:**\n",
        "\n",
        "**1. Standardization:**\n",
        "A z-score indicates how many standard deviations a data point is from the mean of its respective distribution. For example, a z-score of 2 means the data point is two standard deviations above the mean.\n",
        "\n",
        "**2. Common Scale:**\n",
        "By converting data points to z-scores, they are all expressed on a common scale (z-scores), allowing for direct comparison across different distributions.\n",
        "\n",
        "**3. Identifying Extremes:**\n",
        "Z-scores help identify data points that are unusually high or low within their respective distributions, which can be useful in outlier detection or statistical analysis.\n",
        "\n",
        "**4. Probability Calculations:**\n",
        "Z-scores can be used to estimate the probability of a data point falling within a certain range of the mean, which can be helpful in making inferences about the data.\n",
        "\n",
        "###**In essence, z-scores act as a translator, enabling you to compare data points from different distributions on a unified scale of standard deviations from their respective means.**\n",
        "\n",
        "\n",
        "##**21.What are the assumptions for applying the Central Limit Theorem?**\n",
        "##**Ans.-**\n",
        "**The Central Limit Theorem** (CLT) has a few key assumptions to ensure its validity in practical applications. Primarily, the samples should be drawn independently and randomly from the population, and the sample size needs to be sufficiently large (often considered 30 or more). Additionally, the population from which the samples are drawn should have a finite variance.\n",
        "\n",
        "###**Here's a more detailed breakdown of the assumptions:**\n",
        "**Random Sampling:**\n",
        "The samples must be drawn randomly from the population, ensuring that each member of the population has an equal chance of being selected.\n",
        "\n",
        "**Independence:**\n",
        "The samples should be independent of each other, meaning the selection of one sample does not influence the selection of other samples.\n",
        "\n",
        "**Large Sample Size:**\n",
        "A sufficiently large sample size is crucial for the CLT to apply. Investopedia suggests that sample sizes of 30 or more are often considered sufficient. However, with strongly skewed population distributions, even larger sample sizes might be needed.\n",
        "\n",
        "**Finite Variance:**\n",
        "The population from which the samples are drawn must have a finite variance, meaning the variability in the population is bounded.\n",
        "\n",
        "**Sampling without Replacement:**\n",
        "When sampling is done without replacement (meaning once a sample is selected, it cannot be selected again), the sample size should not exceed 10% of the total population.\n",
        "\n",
        "\n",
        "##**22.What is the concept of expected value in a probability distribution?**\n",
        "##**Ans.-**\n",
        "In a probability distribution, the expected value, also known as the mean or average, is a weighted average of all possible values of a random variable. It's the theoretical average you'd expect to get if you repeated the experiment or process generating the random variable many times. The weights in this average are the probabilities of each value occurring.\n",
        "\n",
        "Mathematically, it can be written as:\n",
        "\n",
        "###**E(x) = Σ (x * P(x))**\n",
        "\n",
        "**Long-Term Average:**\n",
        " The expected value represents the average outcome you would expect to see if you repeated the experiment many times. It's a measure of central tendency, meaning it's a value around which the results of the experiment tend to cluster.\n",
        "\n",
        "\n",
        "##**23.How does a probability distribution relate to the expected outcome of a random variable?**  \n",
        "##**Ans.-**\n",
        "A probability distribution describes how probabilities are allocated to the possible values of a random variable. The expected value of a random variable is calculated by weighting each possible outcome by its probability, as defined by the probability distribution, and then summing these weighted outcomes.\n",
        "\n",
        "In essence, the probability distribution provides the framework for calculating the expected value, which represents the long-term average outcome of the random variable.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zbT0t6zbvCla"
      }
    }
  ]
}